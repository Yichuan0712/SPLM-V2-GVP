{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "293abfc9",
      "metadata": {
        "id": "293abfc9"
      },
      "source": [
        "# **S-PLM v2: Quickstart**\n",
        "\n",
        "This notebook is a **usage example** of **S-PLM v2**.\n",
        "\n",
        "* **Purpose:**\n",
        "\n",
        "    1. Process PDB structures into the standardized inputs expected by our model.\n",
        "    \n",
        "    2. Generate **protein-level** and **residue-level** embeddings.\n",
        "    \n",
        "    3. Run sample evaluations and export metrics/logs.\n",
        "* **Checkpoint:** An S-PLM v2 `.pth` checkpoint. Download from the provided [SharePoint link](https://mailmissouri-my.sharepoint.com/:u:/g/personal/wangdu_umsystem_edu/EUZ74fO3NOxHjTvc6uvKwDsB5fELaaw-oiPHFU9CJky_hg?e=4phwL0).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Environment Setup**\n",
        "\n",
        "We **recommend** using an NVIDIA **A100** in Colab; other GPUs/CPU will work but may be slower or run into memory limits.\n"
      ],
      "metadata": {
        "id": "J0Zx6LDn_ZEu"
      },
      "id": "J0Zx6LDn_ZEu"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HU13-POZAdiU"
      },
      "id": "HU13-POZAdiU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf665391",
      "metadata": {
        "id": "cf665391",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Clone S-PLM\n",
        "!git clone -q https://github.com/Yichuan0712/SPLM-V2-GVP /content/SPLMv2\n",
        "\n",
        "# Install minimal deps\n",
        "!pip install 'git+https://github.com/facebookresearch/esm.git' -q\n",
        "!pip install 'git+https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup' -q\n",
        "!pip install biopython -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"torch==2.5.0\" \"torchvision==0.20.0\" \"torchaudio==2.5.0\" \\\n",
        "  --index-url https://download.pytorch.org/whl/cu121\n",
        "import torch\n",
        "TORCH = \"2.5.0\"\n",
        "CUDA = \"cu\" + torch.version.cuda.replace(\".\", \"\")\n",
        "whl_url = f\"https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\"\n",
        "print(\"Using wheel URL:\", whl_url)\n",
        "!pip install -q pyg_lib torch-scatter torch-sparse torch-cluster torch-spline-conv \\\n",
        "    -f {whl_url}\n",
        "!pip install -q torch-geometric"
      ],
      "metadata": {
        "id": "9LGjoCZrUEKO"
      },
      "id": "9LGjoCZrUEKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "!git pull origin main"
      ],
      "metadata": {
        "id": "kf2gKiczjDX2"
      },
      "id": "kf2gKiczjDX2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3efac75f",
      "metadata": {
        "id": "3efac75f"
      },
      "source": [
        "### **Prepare Checkpoint**\n",
        "\n",
        "1. **Download the model** from the provided **[SharePoint link](https://mailmissouri-my.sharepoint.com/:u:/g/personal/wangdu_umsystem_edu/EUZ74fO3NOxHjTvc6uvKwDsB5fELaaw-oiPHFU9CJky_hg?e=4phwL0)** to your local machine.\n",
        "2. **Upload to your Colab runtime** (Files pane → Upload to session storage), then set:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"/content/checkpoint_0280000_gvp.pth\""
      ],
      "metadata": {
        "id": "U-SK-aJNDnXy"
      },
      "id": "U-SK-aJNDnXy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Faster option (recommended):** Mount Google Drive and copy the checkpoint from Drive into the Colab runtime.\n"
      ],
      "metadata": {
        "id": "YLdBSzFSDqcc"
      },
      "id": "YLdBSzFSDqcc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba12f7e",
      "metadata": {
        "id": "1ba12f7e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "import os, shutil\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "shutil.copy(\"/content/drive/MyDrive/checkpoint_0280000_gvp.pth\",\n",
        "            \"/content/checkpoint_0280000_gvp.pth\")\n",
        "CHECKPOINT_PATH = \"/content/checkpoint_0280000_gvp.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate Sequence Embeddings**\n",
        "\n",
        "Use GVP model to generate embeddings from FASTA sequences, with optional truncation and residue-level outputs.\n",
        "\n",
        "* **Standard run:** produces **protein-level** embeddings from `.fasta` to `.pkl`\n",
        "* **Truncated run:** sets `--truncate_inference 1 --max_length_inference 1022` to handle long sequences\n",
        "\n",
        "* **Residue-level run:** adds `--residue_level`\n",
        "\n",
        "**Inputs:** `--input_seq` (FASTA), `--config_path`, `--checkpoint_path`.\n",
        "\n",
        "**Outputs:** pickled embeddings in the working directory (per protein or per residue, depending on flags).\n"
      ],
      "metadata": {
        "id": "q1yTNCuHcBZg"
      },
      "id": "q1yTNCuHcBZg"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "\n",
        "# standard run\n",
        "!python3 -m utils.generate_seq_embedding --input_seq /content/SPLMv2/dataset/protein.fasta \\\n",
        "  --config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml \\\n",
        "  --checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "  --result_path ./"
      ],
      "metadata": {
        "id": "jrvxaxx2cqYS"
      },
      "id": "jrvxaxx2cqYS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "\n",
        "# truncate_inference with max_length_inference=1022\n",
        "!python3 -m utils.generate_seq_embedding --input_seq /content/SPLMv2/dataset/protein.fasta \\\n",
        "--config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml \\\n",
        "--checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "--result_path ./ --out_file truncate_protein_embeddings.pkl \\\n",
        "--truncate_inference 1 --max_length_inference 1022\n",
        "\n",
        "import pickle\n",
        "with open('truncate_protein_embeddings.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "NPrg8OANcp8_"
      },
      "id": "NPrg8OANcp8_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "\n",
        "# residue_level representations\n",
        "!python3 -m utils.generate_seq_embedding --input_seq /content/SPLMv2/dataset/protein.fasta \\\n",
        "--config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml \\\n",
        "--checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "--result_path ./ --out_file truncate_protein_residue_embeddings.pkl \\\n",
        "--truncate_inference 1 --max_length_inference 1022 --residue_level\n",
        "\n",
        "import pickle\n",
        "with open('truncate_protein_residue_embeddings.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "08A-HNiANpy3"
      },
      "id": "08A-HNiANpy3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Preprocess PDB**\n",
        "\n",
        "First preprocess your PDB files using the provided script; only the resulting HDF5 files can be fed into the S-PLM v2 GVP model.\n"
      ],
      "metadata": {
        "id": "q4rR2G6YZW1l"
      },
      "id": "q4rR2G6YZW1l"
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/SPLMv2/data/preprocess_pdb.py --data /content/SPLMv2/dataset/CATH_4_3_0_non-rep_pdbs/ --save_path /content/CATH_4_3_0_non-rep_gvp/ --max_workers 4"
      ],
      "metadata": {
        "id": "a9GgXHBGTluN"
      },
      "id": "a9GgXHBGTluN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate Structure Embeddings**\n",
        "\n",
        "Use GVP model to produce **residue-level structure embeddings** from **preprocessed HDF5** inputs and save them to `protein_struct_embeddings.pkl`, then quickly print the loaded result for inspection.\n",
        "\n",
        "**Inputs:** `--hdf5_path` (preprocessed data), `--config_path`, `--checkpoint_path`.\n",
        "\n",
        "**Output:** `protein_struct_embeddings.pkl` in the current directory (embeddings per protein/chain).\n",
        "\n",
        "**Note:** You **must preprocess** PDB first, the model only accepts the processed HDF5 tensors.\n"
      ],
      "metadata": {
        "id": "EgL1na1UavMr"
      },
      "id": "EgL1na1UavMr"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "!python -m utils.generate_struct_embedding \\\n",
        "  --hdf5_path /content/CATH_4_3_0_non-rep_gvp/ \\\n",
        "  --config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml \\\n",
        "  --checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "  --result_path ./ \\\n",
        "  --residue_level\n",
        "\n",
        "import pickle\n",
        "with open('protein_struct_embeddings.pkl', 'rb') as f:\n",
        "    print(pickle.load(f))"
      ],
      "metadata": {
        "id": "0lut4qBBEWRE"
      },
      "id": "0lut4qBBEWRE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General clustering evaluation (CATH / Kinase)**\n",
        "\n",
        "We evaluate embedding quality using clustering-based analyses. The evaluation supports both structure embeddings and sequence embeddings. We report both visualizations (t-SNE scatter plots) and quantitative metrics (Calinski–Harabasz, ARI, silhouette).\n",
        "\n",
        "\n",
        "### Inputs\n",
        "\n",
        "* `checkpoint_path`: path to the pretrained model checkpoint (`.pth`)\n",
        "* `config_path`: path to the YAML config used for the checkpoint\n",
        "* Path to the evaluation dataset (format depends on `task`)\n",
        "\n",
        "  * `cath_struct`: preprocessed CATH HDF5 directory, e.g. `dataset/CATH_4_3_0_non-rep_h5/`\n",
        "  * `cath_seq`: CATH FASTA file with CATH codes in headers (e.g., `1.10.10.2080|cath|...`)\n",
        "  * `kinase_seq`: TSV file containing kinase metadata and sequences (e.g., `Kinase_group`, `Kinase_domain`)\n",
        "\n",
        "### What it does\n",
        "* **Computes embeddings** for all samples in the dataset.\n",
        "* **Runs clustering evaluation** at one or more label granularities (e.g., CATH Class / Architecture / Fold, or Kinase Group).\n",
        "* **Generates visualizations**:\n",
        "\n",
        "  * Projects embeddings to 2D using t-SNE and saves scatter plots colored by ground-truth labels.\n",
        "* **Computes clustering metrics**:\n",
        "\n",
        "  * Calinski–Harabasz score (full space and t-SNE 2D)\n",
        "  * Adjusted Rand Index (ARI) using k-means on the t-SNE space\n",
        "  * Silhouette score in the full embedding space\n",
        "* **Saves outputs**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTL9dp1Oc-8y"
      },
      "id": "ZTL9dp1Oc-8y"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "!python cath_with_struct.py --checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "--config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml \\\n",
        "--cath_path /content/SPLMv2/dataset/CATH_4_3_0_non-rep_h5/"
      ],
      "metadata": {
        "id": "oBraoHV89YSj"
      },
      "id": "oBraoHV89YSj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "paths = [\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release/CATHgvp_1.png\",\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release/CATHgvp_2.png\",\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release/CATHgvp_3.png\",\n",
        "]\n",
        "\n",
        "imgs = [Image.open(p) for p in paths]\n",
        "\n",
        "total_width = sum(im.width for im in imgs)\n",
        "max_height = max(im.height for im in imgs)\n",
        "\n",
        "new_img = Image.new(\"RGB\", (total_width, max_height), (255, 255, 255))\n",
        "x = 0\n",
        "for im in imgs:\n",
        "    new_img.paste(im, (x, 0))\n",
        "    x += im.width\n",
        "\n",
        "\n",
        "dpi = 800\n",
        "plt.figure(figsize=(total_width / dpi, max_height / dpi), dpi=dpi)\n",
        "plt.imshow(new_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7a9tRpWel30G"
      },
      "id": "7a9tRpWel30G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "\n",
        "!python cath_with_seq.py \\\n",
        "  --cath_seq ./dataset/Rep_subfamily_basedon_S40pdb.fa \\\n",
        "  --checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "  --config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml"
      ],
      "metadata": {
        "id": "XA1FNH0ZCcgL"
      },
      "id": "XA1FNH0ZCcgL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "paths = [\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release_seq/step_0_CATH_1.png\",\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release_seq/step_0_CATH_2.png\",\n",
        "    \"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/CATH_test_release_seq/step_0_CATH_3.png\",\n",
        "]\n",
        "\n",
        "imgs = [Image.open(p) for p in paths]\n",
        "\n",
        "total_width = sum(im.width for im in imgs)\n",
        "max_height = max(im.height for im in imgs)\n",
        "\n",
        "new_img = Image.new(\"RGB\", (total_width, max_height), (255, 255, 255))\n",
        "x = 0\n",
        "for im in imgs:\n",
        "    new_img.paste(im, (x, 0))\n",
        "    x += im.width\n",
        "\n",
        "\n",
        "dpi = 800\n",
        "plt.figure(figsize=(total_width / dpi, max_height / dpi), dpi=dpi)\n",
        "plt.imshow(new_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rMHOu3nnYAyA"
      },
      "id": "rMHOu3nnYAyA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/SPLMv2')\n",
        "\n",
        "!python kinase_with_seq.py \\\n",
        "  --kinase_path ./dataset/GPS5.0_homo_hasPK_with_kinasedomain.txt \\\n",
        "  --checkpoint_path /content/checkpoint_0280000_gvp.pth \\\n",
        "  --config_path /content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek.yaml\n"
      ],
      "metadata": {
        "id": "Aybj2WDcGsG0"
      },
      "id": "Aybj2WDcGsG0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = Image.open(\"/content/SPLMv2/configs/config_plddtallweight_noseq_rotary_foldseek/Kinase_test_release_seq/step_0_kinase.png\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aXZxtx5AYSSd"
      },
      "id": "aXZxtx5AYSSd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "J0Zx6LDn_ZEu",
        "3efac75f"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}